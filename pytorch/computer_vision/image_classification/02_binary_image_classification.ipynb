{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision - Binary Image Classification\n",
    "\n",
    "By [Akshaj Verma](https://akshajverma.com)\n",
    "\n",
    "This notebook takes you through the implementation of binary image classification with CNNs using the hot-dog/not-dog dataset on PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Paths and Set GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the path for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"We're using =>\", device)\n",
    "\n",
    "root_dir = \"../../../data/computer_vision/image_classification/hot-dog-not-hot-dog/\"\n",
    "print(\"The data lies here =>\", root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a dictionary to hold the image transformations for train/test sets. We will resize all images to have size (224, 224) as well as convert the images to tensor. The `ToTensor` operation in PyTorch convert all tensors to lie between (0, 1). \n",
    "\n",
    "> `ToTensor` converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "#         transforms.Normalize([0.5, 0.5, 0.5],\n",
    "#                              [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "#         transforms.Normalize([0.5, 0.5, 0.5],\n",
    "#                              [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train + Validation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We 2 dataset folders with us - **Train** and **Test**. \n",
    "\n",
    "We will further divide our **Train** set as **Train + Val**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdog_dataset = datasets.ImageFolder(root = root_dir + \"train\",\n",
    "                                      transform = image_transforms[\"train\"]\n",
    "                                     )\n",
    "\n",
    "hotdog_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class <=> ID Mapping of Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `class_to_idx` function is pre-built in PyTorch. It returns class ID's present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdog_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now construct a reverse of this dictionary; a mapping of ID to class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2class = {v: k for k, v in hotdog_dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also write a function that takes in a dataset object and returns a dictionary that contains the count of class samples. We will use this dictionary to contruct plots and observe the class distribution in our data.\n",
    "\n",
    "`get_class_distribution()` takes in an argument called `dataset_obj`. \n",
    "\n",
    "* We first initialize a `count_dict` dictionary where counts of all classes are initialised to 0. \n",
    "* Then, let's iterate through the dataset and increment the counter by 1 for every class label encountered in the loop.\n",
    "\n",
    "\n",
    "`plot_from_dict()` takes in 3 arguments: a dictionary called `dict_obj`, `plot_title`, and `**kwargs`. We pass in `**kwargs` because later on, we will constuct subplots which require passing the `ax` argument in seaborn. \n",
    "\n",
    "* First convert the dictionary to a dataframe. \n",
    "* Melt the dataframe and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution(dataset_obj):\n",
    "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
    "    \n",
    "    for _, label_id in dataset_obj:\n",
    "        label = idx2class[label_id]\n",
    "        count_dict[label] += 1\n",
    "    return count_dict\n",
    "\n",
    "\n",
    "def plot_from_dict(dict_obj, plot_title, **kwargs):\n",
    "    return sns.barplot(data = pd.DataFrame.from_dict([dict_obj]).melt(), x = \"variable\", y=\"value\", hue=\"variable\", **kwargs).set_title(plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plot_from_dict(get_class_distribution(hotdog_dataset), plot_title=\"Entire Dataset (before train/val/test split)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train and Validation Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `SubsetRandomSampler` to make our train and validation loaders. `SubsetRandomSampler` is used so that our each batch receives a random distribution of classes. \n",
    "\n",
    "We could've also split our dataset into 2 parts - train and val ie. make 2 `Subsets`. But this is simpler because our data loader will pretty much handle everything now.\n",
    "\n",
    "\n",
    "\n",
    "`SubsetRandomSampler(indices)` takes as input the indices of data.\n",
    "\n",
    "We first create our samplers and then we'll pass it to our dataloaders.\n",
    "\n",
    "* Create a list of indices.\n",
    "* Shuffle the indices.\n",
    "* Split the indices based on train-val percentage.\n",
    "* Create SubsetRandomSampler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of indices from 0 to length of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdog_dataset_size = len(hotdog_dataset)\n",
    "hotdog_dataset_indices = list(range(hotdog_dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the list of indices using np.shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(hotdog_dataset_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the split index. We choose the split index to be 20% (0.2) of the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split_index = int(np.floor(0.2 * hotdog_dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice the lists to obtain 2 lists of indices, one for train and other for test.\n",
    "\n",
    "    0-----------val_split_index------------------------------n\n",
    "\n",
    "Train => val_split_index to n\n",
    "\n",
    "Val => 0 to val_split_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = hotdog_dataset_indices[val_split_index:], hotdog_dataset_indices[:val_split_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create samplers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're done with train and val data, let's load our test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdog_dataset_test = datasets.ImageFolder(root = root_dir + \"test\",\n",
    "                                            transform = image_transforms[\"test\"]\n",
    "                                           )\n",
    "\n",
    "hotdog_dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation, and Test Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will pass the samplers to our dataloader. Note that `shuffle=True` cannot be used when you're using the `SubsetRandomSampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=hotdog_dataset, shuffle=False, batch_size=8, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset=hotdog_dataset, shuffle=False, batch_size=1, sampler=val_sampler)\n",
    "test_loader = DataLoader(dataset=hotdog_dataset_test, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore our train and val dataloaders, let's create a new function that takes in a dataloader and returns a dictionar with class counts. \n",
    "\n",
    "* Intialize a dictionary `count_dict` to all 0s.\n",
    "* If the batch_size of the `dataloader_obj` is 1, then loop through the `dataloader_obj` and update the counter. \n",
    "* Else, if the batch_size of the `dataloader_obj` is **not** 1, then loop through the `dataloader_obj` to obtain batches. Loop through the batches to obtain individual tensors. Now, updated the counter accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution_loaders(dataloader_obj, dataset_obj):\n",
    "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
    "    \n",
    "    if dataloader_obj.batch_size == 1:    \n",
    "        for _,label_id in dataloader_obj:\n",
    "            y_idx = label_id.item()\n",
    "            y_lbl = idx2class[y_idx]\n",
    "            count_dict[str(y_lbl)] += 1\n",
    "    else: \n",
    "        for _,label_id in dataloader_obj:\n",
    "            for idx in label_id:\n",
    "                y_idx = idx.item()\n",
    "                y_lbl = idx2class[y_idx]\n",
    "                count_dict[str(y_lbl)] += 1\n",
    "        \n",
    "            \n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the class distributions, we will use the `plot_from_dict()` function defined earlier with the `ax` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18,7))\n",
    "\n",
    "plot_from_dict(get_class_distribution_loaders(train_loader, hotdog_dataset), plot_title=\"Train Set\", ax=axes[0])\n",
    "plot_from_dict(get_class_distribution_loaders(val_loader, hotdog_dataset), plot_title=\"Val Set\", ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at the class distributions, Let's now look at a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`single_batch` is a list of 2 elements. The first element (0th index) contains the image tensors while the second element (1st index) contains the output labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the first element of the list which is a tensor. This tensor is of the shape `(batch, channels, height, width)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the output labels for the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Output label tensors: \", single_batch[1])\n",
    "print(\"\\nOutput label tensor shape: \", single_batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the image, we'll use `plt.imshow` from matloptlib. It expects the image dimension to be `(height, width, channels)`. We'll `.permute()` our single image tensor to plot it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the first image tensor from the batch. \n",
    "single_image = single_batch[0][0]\n",
    "single_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(single_image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch has made it easier for us to plot the images in a grid straight from the batch. \n",
    "\n",
    "We first extract out the image tensor from the list (returned by our dataloader) and set `nrow`. Then we use the `plt.imshow()` function to plot our grid. Remember to `.permute()` the tensor dimensions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do single_batch[0] because each batch is a list \n",
    "# where the 0th index is the image tensor and 1st index is the output label.\n",
    "single_batch_grid = utils.make_grid(single_batch[0], nrow=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(single_batch_grid.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our architecture is simple. We use 4 blocks of Conv layers. Each block consists of`Convolution` + `BatchNorm` + `ReLU` + `Dropout` layers.\n",
    "\n",
    "\n",
    "We will not use an `FC` layer at the end. We'll stick with a `Conv` layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HotDogClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HotDogClassifier, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.block1 = self.conv_block(c_in=3, c_out=256, dropout=0.1, kernel_size=5, stride=1, padding=2)\n",
    "        self.block2 = self.conv_block(c_in=256, c_out=128, dropout=0.1, kernel_size=3, stride=1, padding=1)\n",
    "        self.block3 = self.conv_block(c_in=128, c_out=64, dropout=0.1, kernel_size=3, stride=1, padding=1)\n",
    "        self.lastcnn = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=56, stride=1, padding=0)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.block2(x)\n",
    "    \n",
    "        x = self.block3(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.lastcnn(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def conv_block(self, c_in, c_out, dropout,  **kwargs):\n",
    "        seq_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c_in, out_channels=c_out, **kwargs),\n",
    "            nn.BatchNorm2d(num_features=c_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=dropout)\n",
    "        )\n",
    "        \n",
    "        return seq_block        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll initialize the model, optimizer, and loss function. \n",
    "\n",
    "Then we'll transfer the model to GPU. \n",
    "\n",
    "We're using the `nn.CrossEntropyLoss` even though it's a binary classification problem. This means, instead of returning a single output of `1/0`, we'll treat return 2 values of `0 and 1`. More specifically, probabilities of the output being either `1` or `0`.\n",
    "\n",
    "We don't have to manually apply a `log_softmax` layer after our final layer because `nn.CrossEntropyLoss` does that for us.\n",
    "\n",
    "However, we need to apply `log_softmax` for our validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HotDogClassifier()\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start our training, let's define a function to calculate accuracy per epoch. \n",
    "\n",
    "This function takes `y_pred` and `y_test` as input arguments. We then apply softmax to `y_pred` and extract the class which has a higher probability.\n",
    "\n",
    "After that, we compare the the predicted classes and the actual classes to calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_tag, dim = 1)\n",
    "    \n",
    "    correct_results_sum = (y_pred_tags == y_test).sum().float()\n",
    "    \n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also define 2 dictionaries which will store the accuracy/epoch and loss/epoch for both train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's TRAIN our model!\n",
    "\n",
    "You can see we've put a `model.train()` at the before the loop. `model.train()` tells PyTorch that you're in training mode. Well, why do we need to do that? If you're using layers such as `Dropout` or `BatchNorm` which behave differently during training and evaluation (for eample; not use `dropout` during evalualtion), you need to tell PyTorch to act accordingly. While the default mode in PyTorch is the train, so, you don't explicitly have to write that. But it's good practice.\n",
    "\n",
    "Similarly, we'll call `model.eval()` when we test our model. We'll see that below. Back to training; we start a for-loop. At the top of this for-loop, we initialize our loss and accuracy per epoch to 0. After every epoch, we'll print out the loss/accuracy and reset it back to 0.\n",
    "\n",
    "Then we have another for-loop. This for-loop is used to get our data in batches from the `train_loader`.\n",
    "\n",
    "We do `optimizer.zero_grad()` before we make any predictions. Since the `.backward()` function accumulates gradients, we need to set it to 0 manually per mini-batch. From our defined model, we then obtain a prediction, get the loss(and accuracy) for that mini-batch, perform backpropagation using loss.backward() and optimizer.step().  \n",
    "\n",
    "\n",
    "Finally, we add all the mini-batch losses (and accuracies) to obtain the average loss (and accuracy) for that epoch. We add up all the losses/accuracies for each minibatch and finally divide it by the number of minibatches ie. length of trainloader to obtain the average loss/accuracy per epoch.\n",
    "\n",
    "The procedure we follow for training is the exact same for validation except for the fact that we wrap it up in `torch.no_grad` and not perform any backpropagation. `torch.no_grad()` tells PyTorch that we do not want to perform back-propagation, which reduces memory usage and speeds up computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Begin training.\")\n",
    "\n",
    "for e in tqdm(range(1, 21)):\n",
    "    \n",
    "    # TRAINING\n",
    "    \n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_train_pred = model(X_train_batch).squeeze()\n",
    "        \n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = binary_acc(y_train_pred, y_train_batch)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "        \n",
    "        \n",
    "    # VALIDATION\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            \n",
    "            y_val_pred = model(X_val_batch).squeeze()\n",
    "            y_val_pred = torch.unsqueeze(y_val_pred, 0)\n",
    "                                    \n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_acc = binary_acc(y_val_pred, y_val_batch)\n",
    "            \n",
    "            val_epoch_loss += train_loss.item()\n",
    "            val_epoch_acc += train_acc.item()\n",
    "\n",
    "    \n",
    "        \n",
    "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
    "                              \n",
    "    \n",
    "    print(f'Epoch {e+0:02}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Loss and Accuracy\n",
    "\n",
    "To plot the loss and accuracy line plots, we again create a dataframe from the `accuracy_stats` and `loss_stats` dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_acc_df = pd.DataFrame.from_dict(accuracy_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
    "train_val_loss_df = pd.DataFrame.from_dict(loss_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(30,10))\n",
    "sns.lineplot(data=train_val_acc_df, x = \"epochs\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Train-Val Accuracy/Epoch')\n",
    "sns.lineplot(data=train_val_loss_df, x = \"epochs\", y=\"value\", hue=\"variable\", ax=axes[1]).set_title('Train-Val Loss/Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "After training is done, we need to test how our model fared. Note that we've used `model.eval()` before we run our testing code.\n",
    "To tell PyTorch that we do not want to perform back-propagation during inference, we use `torch.no_grad()`, just like we did it for the validation loop above.\n",
    "\n",
    "* We start by defining a list that will hold our predictions. Then we loop through our batches using the `test_loader`. For each batch -\n",
    "* We move our input mini-batch to GPU.\n",
    "* We make the predictions using our trained model.\n",
    "* Apply log_softmax activation to the predictions and pick the index of highest probability.\n",
    "* Move the batch to the GPU from the CPU.\n",
    "* Convert the tensor to a numpy object and append it to our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in tqdm(test_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        y_test_pred = model(x_batch)\n",
    "        \n",
    "        y_test_pred = torch.log_softmax(y_test_pred, dim=1)\n",
    "        _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n",
    "    \n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        y_true_list.append(y_batch.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll flatten out the list so that we can use it as an input to `confusion_matrix` and `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = [i[0][0][0] for i in y_pred_list]\n",
    "y_true_list = [i[0] for i in y_true_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we print out the classification report which contains the precision, recall, and the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_true_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dataframe from the confusion matrix and plot it as a heatmap using the seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true_list, y_pred_list)).rename(columns=idx2class, index=idx2class)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,5))         \n",
    "sns.heatmap(confusion_matrix_df, annot=True, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
